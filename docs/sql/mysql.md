## 1. Mysql索引会失效的几种情况分析

*   不满足最左匹配原则
*   使用了select \*
*   在索引列上做任何操作，如计算、函数、（自动or手动）类型转换等操作，会导致索引失效从而全表扫描
*   索引范围条件右边的索引列会失效
*   尽量使用覆盖索引只访问索引查询（索引列和查询列一致），减少select\*
*   使用不等于（!=、<>）mysql在使用不等于（!=、<>）的时候无法使用索引会导致全表扫描（除覆盖索引外）
*   like以通配符开头（'%abc'）索引失效
*   字符串不加单引号索引失效
*   or连接
*   order by

## 2. 什么是元组, 码, 候选码, 主码, 外码, 主属性, 非主属性？

*   **元组** ： 元组（tuple）是关系数据库中的基本概念，关系是一张表，表中的每行（即数据库中的每条记录）就是一个元组，每列就是一个属性。 在二维表里，元组也称为行。
*   **码** ：码就是能唯一标识实体的属性，对应表中的列。
*   **候选码** ： 若关系中的某一属性或属性组的值能唯一的标识一个元组，而其任何、子集都不能再标识，则称该属性组为候选码。例如：在学生实体中，“学号”是能唯一的区分学生实体的，同时又假设“姓名”、“班级”的属性组合足以区分学生实体，那么{学号}和{姓名，班级}都是候选码。
*   **主码** : 主码也叫主键。主码是从候选码中选出来的。 一个实体集中只能有一个主码，但可以有多个候选码。
*   **外码** : 外码也叫外键。如果一个关系中的一个属性是另外一个关系中的主码则这个属性为外码。
*   **主属性** ： 候选码中出现过的属性称为主属性。比如关系 工人（工号，身份证号，姓名，性别，部门）. 显然工号和身份证号都能够唯一标示这个关系，所以都是候选码。工号、身份证号这两个属性就是主属性。如果主码是一个属性组，那么属性组中的属性都是主属性。
*   **非主属性：** 不包含在任何一个候选码中的属性称为非主属性。比如在关系——学生（学号，姓名，年龄，性别，班级）中，主码是“学号”，那么其他的“姓名”、“年龄”、“性别”、“班级”就都可以称为非主属性。

## 3. 数据库范式

### 一、第一范式

1NF是对属性的\*\*`原子性`\*\*，要求属性具有原子性，不可再分解；

> 表：字段1、 字段2(字段2.1、字段2.2)、字段3 ......

如学生（学号，姓名，性别，出生年月日），如果认为最后一列还可以再分成（出生年，出生月，出生日），它就不是一范式了，否则就是；

### 二、第二范式

2NF是对记录的\*\*`唯一性`**，要求记录有唯一标识，即实体的唯一性，即**不存在部分依赖\*\*；

> 表：学号、课程号、姓名、学分;

这个表明显说明了两个事务:学生信息, 课程信息;由于非主键字段必须依赖主键，这里**学分依赖课程号**，**姓名依赖与学号**，所以不符合二范式。

**可能会存在问题：**

*   `数据冗余:`，每条记录都含有相同信息；
*   `删除异常：`删除所有学生成绩，就把课程信息全删除了；
*   `插入异常：`学生未选课，无法记录进数据库；
*   `更新异常：`调整课程学分，所有行都调整。

**正确做法:**
学生：`Student`(学号, 姓名)；
课程：`Course`(课程号, 学分)；
选课关系：`StudentCourse`(学号, 课程号, 成绩)。

### 三、第三范式

3NF是对字段的\*\*`冗余性`**，要求任何字段不能由其他字段派生出来，它要求字段没有冗余，即**不存在传递依赖\*\*；

> 表: 学号, 姓名, 年龄, 学院名称, 学院电话

因为存在**依赖传递**: (学号) → (学生)→(所在学院) → (学院电话) 。

**可能会存在问题：**

*   `数据冗余:`有重复值；
*   `更新异常：`有重复的冗余信息，修改时需要同时修改多条记录，否则会出现**数据不一致的情况** 。

**正确做法：**

学生：(学号, 姓名, 年龄, 所在学院)；

学院：(学院, 电话)。

### 四、反范式化

**一般说来，数据库只需满足第三范式（`3NF`）就行了。**

没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，允许冗余，**`达到以空间换时间的目的`**。

〖例〗：如订单表，“金额”这个字段的存在，表明该表的设计不满足第三范式，因为“金额”可以由“单价”乘以“数量”得到，说明“金额”是冗余字段。但是，增加“金额”这个冗余字段，可以提高查询统计的速度，这就是以空间换时间的作法。

在`Rose 2002`中，规定列有两种类型：**数据列**和**计算列**。“金额”这样的列被称为“计算列”，而“单价”和“数量”这样的列被称为“数据列”。

## 4.数据库的存储引擎

*   InnoDB存储引擎(默认存储引擎)

支持事务安全表(ACID)，支持行锁定（可以提升多用户并发时的读写性能）和外键（保持数据的一致性和完整性），设计遵循ACID模型，支持事务，具有从服务崩溃中恢复数据的能力，能够大限度包含用户的数据，innoDB拥有自己独立的缓冲池，常用的数据和索引都在缓存中

*   MyISAM存储引擎

MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事务。默认MyISAM的表会在磁盘中产生三个文件：.frm、.MYD和.MYI，MyISAM单表大支持的数据量是2的64次方条记录每个表多可以建立64个索引

*   MEMORY存储引擎

将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。磁盘中产生一个以表名为名称的.frm文件，只保存表结构如果关闭MySQL服务，此时数据会产生都是rr，max\_head\_table\_size默认16MB

*   ARCHIVE存储引擎

适合对于不经常访问又删除不了的数据做归档储存，.frm文件结构文件，.arz数据文件，插入效率很高，而且占用空间小，ARCHIVE存储引擎只支持INSERT和SELECT操作，不支持UPDATE/DELECT/

*   CSV

在存储数据时，会以逗号作为数据项之间的分隔符。

*   BLACKHOLE

会丢弃写操作，该操作会返回空内容。

*   FEDERATED

将数据存储在远程数据库中，用来访问远程表的存储引擎。

*   NDB

MySQL 集群专用存储引擎

*   MERGE

用来管理由多个 MyISAM 表构成的表集合

## 5.  TRUNCATE

*   truncate (清空数据) : `truncate table 表名` ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。

## 6.drop、delete 与 truncate 区别？

**用法不同**

*   drop(丢弃数据): `drop table 表名` ，直接将表都删除掉，在删除表的时候使用。
*   truncate (清空数据) : `truncate table 表名` ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。
*   delete（删除数据） : `delete from 表名 where 列名=值`，删除某一列的数据，如果不加 where 子句和`truncate table 表名`作用类似。

truncate 和不带 where 子句的 delete、以及 drop 都会删除表内的数据，但是 **truncate 和 delete 只删除数据不删除表的结构(定义)，执行 drop 语句，此表的结构也会删除，也就是执行 drop 之后对应的表不复存在。**

**属于不同的数据库语言**

truncate 和 drop 属于 DDL(数据定义语言)语句，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger。而 delete 语句是 DML (数据库操作语言)语句，这个操作会放到 rollback segement 中，事务提交之后才生效。

## 7. 事务的ACID属性

**ACID简介**

为了保持数据库的一致性，在事务处理之前和之后，都遵循某些属性，也就是大家耳熟能详的ACID属性：

*   原子性（Atomicity）：即不可分割性，事务中的操作要么全不做，要么全做
*   一致性（Consistency）：一个事务在执行前后，数据库都必须处于正确的状态，满足完整性约束
*   隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行
*   持久性（Durability）：事务处理完成后，对数据的修改就是永久的，即便系统故障也不会丢失

## 8. utf8和utf8mb4

MySQL 字符编码集中有两套 UTF-8 编码实现：

*   **`utf8`** ： `utf8`编码只支持`1-3`个字节 。 在 `utf8` 编码中，中文是占 3 个字节，其他数字、英文、符号占一个字节。但 emoji 符号占 4 个字节，一些较复杂的文字、繁体字也是 4 个字节。
*   **`utf8mb4`** ： UTF-8 的完整实现，正版！最多支持使用 4 个字节表示字符，因此，可以用来存储 emoji 符号。

## 9.MyISAM 和 InnoDB 的区别

*   InnoDB支持表、行级锁，而MyISAM支持表级锁。

*   是否支持事务

*   是否支持外键

*   是否支持数据库异常崩溃后的安全恢复

*   是否支持 MVCC

*   InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引

MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。

> MyISAM

有两个文件，一个`user_myisam_MYI`----`index`与`user_myisam_MYD`----`data`

它是数据文件与索引文件分开的


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4a8ddbbe6d7e4b2c9f4c9617782df6eb~tplv-k3u1fbpfcp-watermark.image?)
左边就是MYI右边就是MYD

`有多少个索引MYI文件里面就有多少颗B+树，无论是主键索引还是辅助索引，没有级别划分`，比如查找id为3的数据，一路向下查找，根据地址值再找到id为3的完整数据，从索引到数据的一个检索流程就是MYISAM的检索流程。

> innoDB 数据即索引

它只有一个文件


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6550a86be2144d8cbeceec82c8143171~tplv-k3u1fbpfcp-watermark.image?)

## 10. MySQL索引主要使用的两种数据结构

*   哈希索引

对于哈希索引来说，底层的数据结构肯定是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

*   BTree索引

Mysql的BTree索引使用的是B树中的B+Tree，BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。

## 11 MySQL 中事务的隔离级别

*   SQL 标准定义了四个隔离级别：

    *   **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
    *   **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
    *   **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
    *   **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

    ***

    |       隔离级别       |  脏读 | 不可重复读 |  幻读 |
    | :--------------: | :-: | :---: | :-: |
    | READ-UNCOMMITTED |  √  |   √   |  √  |
    |  READ-COMMITTED  |  ×  |   √   |  √  |
    |  REPEATABLE-READ |  ×  |   ×   |  √  |
    |   SERIALIZABLE   |  ×  |   ×   |  ×  |

## 12. mysql并发情况下引起的事务的安全问题有哪些?

*   脏读

一个事务读取另一个事务未提交的问题

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b5d4c74278e249d4a2404909e9ea5d2f~tplv-k3u1fbpfcp-watermark.image?)

*   丢失修改（Lost to modify）:

指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。

*   不可重复读

在同一事务中，两次读取同一数据，得到内容不同

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6e4605ad4c5d41619c5f7f24ec9fb10c~tplv-k3u1fbpfcp-watermark.image?)


*   幻读

同一事务中，用同样的操作读取两次，得到的记录数不相同


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/13adc856304c4a238d6403e80dfb32ec~tplv-k3u1fbpfcp-watermark.image?)

> 总结

不可重复读是修改或者删除，幻读是插入

无论是脏读、不可重复读、幻读，它们都是数据库的读一致性的问题，都是一个事务里面前后两次读取出现了不一致的情况；

## 13. mysql的默认的RR(允许重复度)隔离级别下,如何避免事务的安全问题?

在mysql的innodb的引擎下,采用MVCC机制+锁 方式解决事务的安全问题,但在RR(允许重复读)的级别下没有完全解决幻读的问题.

*   解决脏读

修改时加排他锁(写锁)，直到事务提交后才释放，读取时加共享锁(读锁)，其他事务只能读取，不能再有更新操作 。防止脏读。

*   解决不可重复读

innodb引擎采用了mvcc（多版本并发控制）来解决不可重复读问题。mvcc是利用在每条数据后面加了隐藏的两列（创建版本号和删除版本号）当执行查询的时, 当前查询版本号>= 创建版本号 并且 >删除版本号 , MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销。

*   解决幻读

Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读。

分2种，快照读和当前读

(1)快照读(mvcc) 普通的 select 就是快照读。将历史数据存一份快照，所以其他事务增加与删除数据，对于当前事务来说是不可见的。事务每次取数据的时候都会取创建版本<当前事务的数据，以及删除版本号码>当前版本的数据。

(2)当前读 执行数据库的增删改操作的时, 就是当前读

采用next-key锁的方式解决问题

next-key 锁包含两部分: 记录锁（行锁）+ 间隙锁 就是在索引和索引之间上面加锁

## 14. mysql查询缓存

执行查询语句的时候，会先查询缓存。不过，MySQL 8.0 版本后移除，因为这个功能不太实用

`my.cnf` 加入以下配置，重启 MySQL 开启查询缓存

```properties
query_cache_type=1
query_cache_size=600000
```

MySQL 执行以下命令也可以开启查询缓存

```properties
set global  query_cache_type=1;
set global  query_cache_size=600000;
```

**开启查询缓存后在同样的查询条件以及数据情况下，会直接在缓存中返回结果**。这里的查询条件包括查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息。

**查询缓存不命中的情况：**

（1）因此任何两个查询在任何字符上的不同都会导致缓存不命中。

（2）如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存。

（3）缓存建立之后，MySQL 的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。

*   **缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。**

因此，开启查询缓存要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十 MB 比较合适。此外，**还可以通过 sql\_cache 和 sql\_no\_cache 来控制某个查询语句是否需要缓存：**

```sql
select sql_no_cache count(*) from usr;
```

## 15. SQL优化

### 15.1 SQL语句编写优化

<https://juejin.cn/post/7164652941159170078#heading-6>

1.  查询时尽量不要使用\*
2.  连表查询时尽量不要关联太多表
3.  多表查询时一定要以小驱大
4.  不要使用like左模糊和全模糊查询
5.  查询时尽量不要对字段做空值判断
6.  不要在条件查询=前对字段做任何运算
7.  !=、!<>、not in、not like、or...要慎用
8.  避免频繁创建、销毁临时表
9.  尽量将大事务拆分为小事务执行
10. 从业务设计层面减少大量数据返回的情况
11. 尽量避免深分页的情况出现

### 15.2 索引优化

## 16. 索引的设计

> 常见索引有哪些？

*   普通索引：最基本的索引，没有任何限制
*   唯一索引：与”普通索引“类似，不同的就是：索引列的值必须是唯一，但允许有空值
*   **Primary Key（聚集索引）**：InnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键，则会使用第一非空的唯一索引作为聚集索引，否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row\_id用来作为聚集索引。
*   全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时占空间
*   **单列索引**：单列索引即一个索引只包含单个列
*   **组合索引**：组合索引指在表的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用。使用组合索引时**遵循最左前缀集合**

> 索引的优点

*   1.加快数据的检索速度，这是创建索引的最主要的原因;
*   2.通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性;
*   3.加速表和表之间的连接;
*   4.在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。

> 索引的缺点

*   1.创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。
*   2.索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
*   3.当对表中的数据进行增加、删除和修改的时候，索引也要同步动态的维护，这样就降低了数据的增删改速度。

> 索引设计原则

1.  索引满足最左匹配原则
2.  为经常需要排序、分组操作的字段建立索引

经常需要ORDER BY、GROUP BY、DISTINCT等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。`分组字段或者排序字段应该创建索引`

3.  为常作为查询条件的字段建立索引

如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为		这样的字段建立索引，可以提高整个表的查询速度。`Where 子句中经常使用的字段应该创建索引`

4.  限制索引数目

索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。

5.  尽量选择区分度高的列作为索引

尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(\*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录

6.  索引列不能参与计算

即索引列不能带函数，否则会导致索引失效

7.  扩展索引

尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可

8.  条件带like 注意事项

like 模糊查询中，右模糊查询(abc%)会使用索引，而(%abc)和(%abc%)会放弃索引而使用全表扫描

9.  尽量使用数据量少的索引

如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间要比对CHAR(10)类型的字段需要的时间要多。

10. 尽量使用前缀来索引

如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。

11. 删除不再使用或者很少使用的索引

表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。

12. 联合查询

联合查询，子查询等多表操作时关连字段要加索引

## 17. Mysql的体系结构是什么样子的（一条查询语句它到底是怎么执行的）


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/009f882d320343d5aac09086acffd5b5~tplv-k3u1fbpfcp-watermark.image?)

*   查询缓存：执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用），它是表级别的，表里面任何一条数据发生变化就会失效

*   语法解析和预处理：

    *   下一步我们要做什么呢？  假如随便执行一个字符串fkdljasklf,
    *   服务器报了一个1064的错：  \[Err]1064-You have an error in your SQL syntax;check the manual that corresponds to your MySQL  server version for the right syntax to use near'fkdljasklf at line 1
    *   服务器是怎么知道我输入的内容是错误的？  或者，当我输入了一个语法完全正确的SQL,但是表名不存在，它是怎么发现的？  这个就是MySQL的`Parser`解析器和`Preprocessor`预处理模块。  这一步主要做的事情是对SQL语句进行词法和语法分析和语义的解析。

    分析器先会做`“词法分析”`。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。

    MySQL从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。

    做完了这些识别以后，就要做`“语法分析”`。

    语法分析会对SQL做一些语法检查，比如单引号有没有闭合，根据mysql定义的语法规则，根据SQL语句生成一个数据结构，这个数据结构就叫做解析树


    根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。

    如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句select少打了开头的字母“s”。

    ```mysql
    mysql> elect * from t where ID=1;

    ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1
    ```

*   预处理器

如果表明错误，会在预处理器处理的时候报错

它会检查生成的解析树，解决解析器无法介意的语义，比如会检查表和列名是否存在，检查名字和别名，保证没有歧义。

*   查询优化器

查询优化器的目的是根据解析树生成不同的执行计划，然后选择一种最优的执行计划，Mysql里面使用的是基于开销(cost)的优化器，哪种执行计划开销最小，就用哪种；

## 17.1 mysql基础架构

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ad706231318b462398b5eb6b6fb5978c~tplv-k3u1fbpfcp-zoom-1.image)

从上图可以看出， MySQL 主要由下面几部分构成：

*   **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
*   **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
*   **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
*   **优化器：** 按照 MySQL 认为最优的方案去执行。
*   **执行器：** 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
*   **插件式存储引擎** ： 主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎。

## 17.2 一条SQL语句在MySQL中如何被执行

*   MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用，redolog 只有 InnoDB 有。
*   引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。
*   查询语句的执行流程如下：权限校验（如果命中缓存）--->查询缓存--->分析器--->优化器--->权限校验--->执行器--->引擎
*   更新语句执行流程如下：分析器---->权限校验---->执行器--->引擎---redo log(prepare 状态)--->binlog--->redo log(commit状态)

## 18. redo log

`redo log`（重做日志）是`InnoDB`存储引擎独有的，它让`MySQL`拥有了崩溃恢复能力。

比如 `MySQL` 实例挂了或宕机了，重启时，`InnoDB`存储引擎会使用`redo log`恢复数据，保证数据的持久性与完整性。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/39f7cf6d671c48fda8369537198ec7c4~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:67%;">

`MySQL` 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 `Buffer Pool` 中。

后续的查询都是先从 `Buffer Pool` 中找，没有命中再去硬盘加载，减少硬盘 `IO` 开销，提升性能。

更新表数据的时候，也是如此，发现 `Buffer Pool` 里存在要更新的数据，就直接在 `Buffer Pool` 里更新。

然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（`redo log buffer`）里，接着刷盘到 `redo log` 文件里。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/158dc1907e4f4912893355e9cd2fc155~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:67%;">

### 刷盘时机

`InnoDB` 存储引擎为 `redo log` 的刷盘策略提供了 `innodb_flush_log_at_trx_commit` 参数，它支持三种策略：

*   **0** ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作
*   **1** ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）
*   **2** ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache

### 日志文件组

硬盘上存储的 `redo log` 日志文件不只一个，而是以一个**日志文件组**的形式出现的，每个的`redo`日志文件大小都是一样的。

比如可以配置为一组`4`个文件，每个文件的大小是 `1GB`，整个 `redo log` 日志文件组可以记录`4G`的内容。

它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写，如下图所示。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0be4af1b00d9414298b25233c0d4404a~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:67%;">

在个**日志文件组**中还有两个重要的属性，分别是 `write pos、checkpoint`

*   **write pos** 是当前记录的位置，一边写一边后移
*   **checkpoint** 是当前要擦除的位置，也是往后推移

## 19. binlog （数据库被人干掉怎么办）

`binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。

不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。

那 `binlog` 到底是用来干嘛的？

binlog的主要作用是数据恢复和主从复制

*   数据恢复

> binlog以事件的形式记录了所有的DDL和DML语句，可以用来做主从复制和数据恢复

> 例如有人删除了数据库的数据，比如是早上10删除的，每天凌晨1点又会进行全量备份，那凌晨1点到10点的数据就可以通过解析binlog日志的sql语句来重新执行，恢复到10点，
>
> 还有一种情况就是比如11点才发现的，那么10点到11点这段时间就需要人工的进行恢复，避免数据货不对板

*   主从复制


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc1543f95f7b4826b99034c64a35c9d4~tplv-k3u1fbpfcp-watermark.image?)

1.  从节点上有个IO线程，会去请求主节点上的Log Dump 线程
2.  Log Dump 线程会把binlog中最近发生变化的内容发送给从节点

> 不直接落到从节点的库上面的原因是有可能从节点请求主节点的时候，主节点已经积攒了很多数据更改，不能直接落在库上，所以需要一个缓冲区，就是应用的一种日志叫relay log

3.  把变更的数据写到relay log缓冲区
4.  SQL 线程主动去读取relay log中的变更数据 均速
5.  再把SQL执行一遍

> 数据恢复：区别于Redo log的崩溃恢复，数据恢复是基于业务数据的，不如删库跑路，而崩溃恢复时比如断电重启，重启后内存的数据还没有同步到磁盘，崩溃恢复是恢复这种数据

### 什么是预读

磁盘读取，并不是按需读取，而是按页读取，一次至少读取一页数据（一般是4K）但是Mysql的数据页是16K，如果未来要读取的数据就在页中，就能够省去后续读取的磁盘IO，提高效率。

### 记录格式

`binlog` 日志有三种格式，可以通过`binlog_format`参数指定。

*   **statement**
*   **row**
*   **mixed**

指定`statement`，记录的内容是`SQL`语句原文，比如执行一条`update T set update_time=now() where id=1`，记录的内容如下。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/99276f1c48d7491aa7748fdcde882f74~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:67%;">

同步数据时，会执行记录的`SQL`语句，但是有个问题，`update_time=now()`这里会获取当前系统时间，直接执行会导致与原库的数据不一致。

为了解决这种问题，我们需要指定为`row`，记录的内容不再是简单的`SQL`语句了，还包含操作的具体数据，记录内容如下。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5064c3eaf9404843a1eab9ddacd0373d~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:67%;">

`row`格式记录的内容看不到详细信息，要通过`mysqlbinlog`工具解析出来。

`update_time=now()`变成了具体的时间`update_time=1627112756247`，条件后面的@1、@2、@3 都是该行数据第 1 个\~3 个字段的原始值（**假设这张表只有 3 个字段**）。

这样就能保证同步数据的一致性，通常情况下都是指定为`row`，这样可以为数据库的恢复与同步带来更好的可靠性。

但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗`IO`资源，影响执行速度。

所以就有了一种折中的方案，指定为`mixed`，记录的内容是前两者的混合。

`MySQL`会判断这条`SQL`语句是否可能引起数据不一致，如果是，就用`row`格式，否则就用`statement`格式。

### 写入机制

`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为`binlog cache`。

我们可以通过`binlog_cache_size`参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（`Swap`）。

`binlog`日志刷盘流程如下

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6101c08372c4155b95ff7935bce5e4d~tplv-k3u1fbpfcp-zoom-1.image)

*   **上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快**
*   **上图的 fsync，才是将数据持久化到磁盘的操作**

`write`和`fsync`的时机，可以由参数`sync_binlog`控制，默认是`0`。

为`0`的时候，表示每次提交事务都只`write`，由系统自行判断什么时候执行`fsync`。

### 两阶段提交

为了解决两份日志之间的逻辑一致问题，`InnoDB`存储引擎使用**两阶段提交**方案。

原理很简单，将`redo log`的写入拆成了两个步骤`prepare`和`commit`，这就是**两阶段提交**。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/282e1aea89604e8da2131934434b5b33~tplv-k3u1fbpfcp-zoom-1.image)

使用**两阶段提交**后，写入`binlog`时发生异常也不会有影响，因为`MySQL`根据`redo log`日志恢复数据时，发现`redo log`还处于`prepare`阶段，并且没有对应`binlog`日志，就会回滚该事务。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/231de49ef4354a4d8846878eec7f297d~tplv-k3u1fbpfcp-zoom-1.image)

## 20. undo log

我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志** 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。

另外，`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改

## 21 MySQL有哪些锁

> 行级锁

行级锁是mysql中锁定粒度最细的一种锁。表示只针对`当前操作的行进行加锁`。行级锁能大大减少数据库操作的冲突，其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁

*   共享锁（读锁）

共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行`修改（获取数据上的排他锁）`，直到已释放所有共享锁。

如果事务T对数据A加上共享锁后，则其他事务`只能对A再加共享锁`，`不能加排他锁`。获准共享锁的事务只能读数据，不能修改数据。

*   排它锁（写锁）

排他锁又称写锁、独占锁，如果事务T对数据A加上排他锁后，`则其他事务不能再对A加任何类型的封锁`。获准排他锁的事务既能读数据，又能修改数据。

> 表级锁

表级锁是mysql中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分mysql引擎支持。最常使用的MyISAM与InnoDB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）

*   意向锁

意向锁是表级锁，其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型。InnoDB 中的两个表锁：

意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁；

意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。

意向锁是 InnoDB 自动加的，不需要用户干预。

> 页级锁

(1) 描述

页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。因此，采取了折衷的页级锁，一次锁定相邻的一组记录。BDB 支持页级锁。

(2)特点

开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

## 22.索引

### 一、索引是什么

*   索引是一种能提高数据库查询效率的数据结构。它可以比作一本字典的目录，可以帮你快速找到对应的记录。
*   索引一般存储在磁盘的文件中，它是占用物理空间的。
*   正所谓水能载舟，也能覆舟。适当的索引能提高查询效率，过多的索引会影响数据库表的插入和更新功能。


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6db7e01d974140cf88386716434e1729~tplv-k3u1fbpfcp-watermark.image?)

### 二、索引有哪些类型类型


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9706d7cf14a0460bb95ba004b6a0ac5a~tplv-k3u1fbpfcp-watermark.image?)

#### 数据结构维度

*   B+树索引：所有数据存储在叶子节点，复杂度为O(logn)，适合范围查询。
*   哈希索引:  适合等值查询，检索效率高，一次到位。
*   全文索引：MyISAM和InnoDB中都支持使用全文索引，一般在文本类型char,text,varchar类型上创建。
*   R-Tree索引: 用来对GIS数据类型创建SPATIAL索引

#### 物理存储维度

*   聚集索引：聚集索引就是以主键创建的索引，在叶子节点存储的是表中的数据。
*   非聚集索引：非聚集索引就是以非主键创建的索引，在叶子节点存储的是主键和索引列。

#### 逻辑维度

*   主键索引：一种特殊的唯一索引，不允许有空值。
*   普通索引：MySQL中基本索引类型，允许空值和重复值。
*   联合索引：多个字段创建的索引，使用时遵循最左前缀原则。
*   唯一索引：索引列中的值必须是唯一的，但是允许为空值。
*   空间索引：MySQL5.7之后支持空间索引，在空间索引这方面遵循OpenGIS几何数据模型规则。

### 三、为什么选择B+树作为索引结构

> B树和B+树的区别


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f46f7bd9a19f4c609b7043a6b76376a0~tplv-k3u1fbpfcp-watermark.image?)

*   `B树`的每个节点，既有Key又有数据；而`B+`树的数据都在叶子节点上，其他节点上只有Key
*
*   `B树`的叶子节点是没有什么关联的；而`B+树`的叶子节点之间互相有引用链路，像链表一样
*   查找的方式也不一样；在`B树`中比如找30，比17大比35小，走中间的指针，然后就能找到30，可能它都不需要经过叶子节点；而`B+`树，30比28大走右边的指针，接着30比36小，走左边的指针，接着在磁盘块7找到30，B+树是需要到叶子节点才能找到数据的；

我们写业务SQL查询时，大多数情况下，都是范围查询的，如下SQL

    select * from employee where age between 18 and 28;

#### 为什么不使用哈希结构？

我们知道哈希结构，类似k-v结构，也就是，key和value是一对一关系。它用于\*\*「等值查询」\*\*还可以，但是范围查询它是无能为力的哦。

#### 为什么不使用二叉树呢？

先回忆下二叉树相关知识啦\~ 所谓\*\*「二叉树，特点如下：」\*\*

*   每个结点最多两个子树，分别称为左子树和右子树。
*   左子节点的值小于当前节点的值，当前节点值小于右子节点值
*   顶端的节点称为根节点，没有子节点的节点值称为叶子节点。

我们脑海中，很容易就浮现出这种二叉树结构图：


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15c78b25e65749c68eb232d6be764fd0~tplv-k3u1fbpfcp-watermark.image?)

但是呢，有些特殊二叉树，它可能这样的哦：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ea7ec4e820648948ee619b5cc65e7c7~tplv-k3u1fbpfcp-watermark.image?)

如果二叉树特殊化为一个链表，相当于全表扫描。那么还要索引干嘛呀？因此，一般二叉树不适合作为索引结构。

#### 为什么不使用平衡二叉树呢？

平衡二叉树特点：它也是一颗二叉查找树，任何节点的两个子树高度最大差为1。所以就不会出现特殊化一个链表的情况啦。

首先什么平衡二叉树是二叉排序树，二叉排序树是


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2db541c0ca30450bacc2dfcfe5434bdd~tplv-k3u1fbpfcp-watermark.image?)

而平衡二叉树是二叉排序树的改进版


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/66211c046391449a9ae9aaa1812ae120~tplv-k3u1fbpfcp-watermark.image?)

所以平衡二叉树是平衡因子的绝对值小于1的二叉排序树

但是呢：

*   平衡二叉树插入或者更新时，需要左旋右旋维持平衡，维护代价大
*   如果数量多的话，树的高度会很高。因为数据是存在磁盘的，以它作为索引结构，每次从磁盘读取一个节点，操作IO的次数就多啦。

#### 为什么不使用B树呢？

数据量大的话，平衡二叉树的高度会很高，会增加IO嘛。那为什么不选择同样数据量，\*\*「高度更矮的B树」\*\*呢？


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e545bed46f8440d69d822e09d3ffb8b6~tplv-k3u1fbpfcp-watermark.image?)

B树相对于平衡二叉树，就可以存储更多的数据，高度更低。但是最后为甚选择B+树呢？因为B+树是B树的升级版：

> B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。
>
> B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。

#### 一次B+树索引搜索过程

假设有以下表结构，并且有这几条数据

```sql
CREATE TABLE `employee` (
  `id` int(11) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  `date` datetime DEFAULT NULL,
  `sex` int(1) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_age` (`age`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

insert into employee values(100,'小伦',43,'2021-01-20','0');
insert into employee values(200,'俊杰',48,'2021-01-21','0');
insert into employee values(300,'紫琪',36,'2020-01-21','1');
insert into employee values(400,'立红',32,'2020-01-21','0');
insert into employee values(500,'易迅',37,'2020-01-21','1');
insert into employee values(600,'小军',49,'2021-01-21','0');
insert into employee values(700,'小燕',28,'2021-01-21','1');
```

如果执行以下的查询SQL，需要执行几次的树搜索操作？可以画下对应的索引结构图\~

select \* from Temployee where age=32;

其实这个，面试官就是考察候选人是否熟悉B+树索引结构图。可以像酱紫回答\~

*   先画出`idx_age`索引的索引结构图，大概如下：


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7bf055d2f3164233998f8ddea9f509f6~tplv-k3u1fbpfcp-watermark.image?)
*   再画出id主键索引，我们先画出聚族索引结构图，如下：


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4a3203a003f649cbab44220c2d7251c6~tplv-k3u1fbpfcp-watermark.image?)

因此，这条 SQL 查询语句执行大概流程就是酱紫：

*   1.  搜索`idx_age`索引树，将磁盘块1加载到内存，由于32<37,搜索左路分支，到磁盘寻址磁盘块2。

2.  将磁盘块2加载到内存中，在内存继续遍历，找到age=32的记录，取得id = 400.

3.  拿到id=400后，回到id主键索引树。

4.  搜索`id主键`索引树，将磁盘块1加载内存，在内存遍历，找到了400，但是B+树索引非叶子节点是不保存数据的。索引会继续搜索400的右分支，到磁盘寻址磁盘块3.

5.  将磁盘块3加载内存，在内存遍历，找到id=400的记录，拿到R4这一行的数据，好的，大功告成。

因此，这个SQL查询，执行了几次树的搜索操作，是不是一步了然了呀。**「特别的」**，在`idx_age`二级索引树找到主键`id`后，回到id主键索引搜索的过程,就称为回表。

> 什么是回表？拿到主键再回到主键索引查询的过程，就叫做\*\*「回表」\*\*

#### 覆盖索引

**「面试官：」** 如果不用`select *`, 而是使用`select id,age`，以上的题目执行了几次树搜索操作呢？

**「解析：」** 这个问题，主要考察候选人的覆盖索引知识点。回到`idx_age`索引树，你可以发现查询选项id和age都在叶子节点上了。因此，可以直接提供查询结果啦，根本就不需要再回表了\~


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/47f73f36a4b948f6a663a11c5eefbf41~tplv-k3u1fbpfcp-watermark.image?)

覆盖索引：在查询的数据列里面，不需要回表去查，直接从索引列就能取到想要的结果。换句话说，你SQL用到的索引列数据，覆盖了查询结果的列，就算上覆盖索引了。

#### 索引失效

**「面试官：」** 如果我现在给`name`字段加上普通索引，然后用个like模糊搜索，那会执行多少次查询呢？SQL如下：

```sql
select * from employee where name like '%杰伦%';
```

**「解析：」** 这里考察的知识点就是，like是否会导致不走索引，看先该SQL的explain执行计划吧。其实like 模糊搜索，会导致不走索引的，如下:


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c32b3b19361b49fb83d8d40e41052421~tplv-k3u1fbpfcp-watermark.image?)

因此，这条SQL最后就全表扫描啦\~日常开发中，这几种骚操作都可能会导致索引失效，如下：

*   查询条件包含or，可能导致索引失效
*   如果字段类型是字符串，where时一定用引号括起来，否则索引失效
*   like通配符可能导致索引失效。
*   联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。
*   在索引列上使用mysql的内置函数，索引失效。
*   对索引列运算（如，+、-、\*、/），索引失效。
*   索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。
*   索引字段上使用is null， is not null，可能导致索引失效。
*   左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。
*   mysql估计使用全表扫描要比使用索引快,则不使用索引。

#### 索引之最左前缀原则

**「面试官：」** 如果我现在给name,age字段加上联合索引，以下SQL执行多少次树搜索呢？先画下索引树？

```sql
select * from employee where name like '小%' order by age desc;
```

**「解析：」** 这里考察联合索引的最左前缀原则以及like是否中索引的知识点。组合索引树示意图大概如下：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b733065052948fdba0583a96316a228~tplv-k3u1fbpfcp-watermark.image?)

联合索引项是先按姓名name从小到大排序，如果名字name相同，则按年龄age从小到大排序。面试官要求查所有名字第一个字是“小”的人，SQL的like '小%'是可以用上`idx_name_age`联合索引的。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6319089a79ff488380d7744ba6919dcc~tplv-k3u1fbpfcp-watermark.image?)

该查询会沿着idx\_name\_age索引树，找到第一个字是小的索引值，因此依次找到`小军、小伦、小燕、`，分别拿到Id=`600、100、700`，然后回三次表，去找对应的记录。这里面的最左前缀`小`，就是字符串索引的最左M个字符。实际上，

*   这个最左前缀可以是联合索引的最左N个字段。比如组合索引（a,b,c）可以相当于建了（a），（a,b）,(a,b,c)三个索引，大大提高了索引复用能力。
*   最左前缀也可以是字符串索引的最左M个字符。

#### 索引下推

**「面试官：」** 我们还是居于组合索引 idx\_name\_age，以下这个SQL执行几次树搜索呢？

```sql
select * from employee where name like '小%' and age=28 and sex='0';
```

**「解析：」** 这里考察索引下推的知识点，如果是\*\*「Mysql5.6之前」\*\*，在idx\_name\_age索引树，找出所有名字第一个字是“小”的人，拿到它们的主键id，然后回表找出数据行，再去对比年龄和性别等其他字段。如图：


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/58e07107dcf74c859e61d6f2555802f0~tplv-k3u1fbpfcp-watermark.image?)

有些朋友可能觉得奇怪，（name,age)不是联合索引嘛？为什么选出包含“小”字后，不再顺便看下年龄age再回表呢，不是更高效嘛？所以呀，MySQL 5.6 就引入了\*\*「索引下推优化」\*\*，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

因此，MySQL5.6版本之后，选出包含“小”字后，顺表过滤age=28，,所以就只需一次回表。


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/08ccc6878ed049ab8285b68ce2a00875~tplv-k3u1fbpfcp-watermark.image?)

#### 大表添加索引

**「面试官：」** 如果一张表数据量级是千万级别以上的，那么，给这张表添加索引，你需要怎么做呢？

**「解析：」** 我们需要知道一点，给表添加索引的时候，是会对表加锁的。如果不谨慎操作，有可能出现生产事故的。可以参考以下方法：

*   1.先创建一张跟原表A数据结构相同的新表B。
*   2.在新表B添加需要加上的新索引。
*   3.把原表A数据导到新表B
*   4.rename新表B为原表的表名A，原表A换别的表名；

## 23. 关于MVCC

### 简单理解

要说幻读，首先要了解MVCC，MVCC叫做多版本并发控制，实际上就是保存了数据在某个时间节点的快照。

我们每行数据实际上隐藏了两列，创建时间版本号，过期(删除)时间版本号，每开始一个新的事务，版本号都会自动递增。

还是拿上面的user表举例子，假设我们插入两条数据，他们实际上应该长这样。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/862ea2d44dd64fc1b874c5a05817faff~tplv-k3u1fbpfcp-zoom-1.image)

这时候假设小明去执行查询，此时current\_version=3

    select * from user where id<=3;

同时，小红在这时候开启事务去修改id=1的记录，current\_version=4

    update user set name='张三三' where id=1;

执行成功后的结果是这样的

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/939a28bafda04a5c87eab0cc67fd3acf~tplv-k3u1fbpfcp-zoom-1.image)

如果这时候还有小黑在删除id=2的数据，current\_version=5，执行后结果是这样的。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7f3b4e9831a648ad87035304e7ad3cdb~tplv-k3u1fbpfcp-zoom-1.image)

由于MVCC的原理是查找创建版本小于或等于当前事务版本，删除版本为空或者大于当前事务版本，小明的真实的查询应该是这样

    select * from user where id<=3 and create_version<=3 and (delete_version>3 or delete_version is null);

所以小明最后查询到的id=1的名字还是'张三'，并且id=2的记录也能查询到。这样做是**为了保证事务读取的数据是在事务开始前就已经存在的，要么是事务自己插入或者修改的**。

### 真正原理

事实上，上述的说法只是简化版的理解，真正的MVCC用于读已提交和可重复读级别的控制，主要通过undo log日志版本链和read view来实现。

每条数据隐藏的两个字段也并不是`创建时间版本号`和`过期(删除)时间版本号`，而是`roll_pointer`和`trx_id`。

roll\_pointer指向更新事务之前生成的undo log，undo log用于事务的回滚，保证事务的原子性。

trx\_id就是最近一次更新数据的事务ID。

以上述例子来举例，最初插入两条数据，真实的情况是这样，因为第一次插入数据没有undo log，所以roll\_pointer指向一个空的undo log。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c1856bf7b6154b79ab57c102c161d80e~tplv-k3u1fbpfcp-zoom-1.image)

这时候假设小明去执行查询，就会开启一个read view，read view包含几个重要的东西。

1.  m\_ids，就是还未提交的事务id集合
2.  low\_limit\_id，m\_ids里最小的值
3.  up\_limit\_id，下一次要生成的事务ID值
4.  creator\_trx\_id，创建read view的事务ID，也就是自己的事务ID

小明来执行查询了，当前事务ID=3

    select * from user where id<=3;

小红在这时候开启事务去修改id=1的记录，事务ID=4

    update user set name='张三三' where id=1;

这时候小明的read view是这样。

> m\_ids=\[3,4]
>
> low\_limit\_id=3
>
> up\_limit\_id=5
>
> creator\_trx\_id=3

所以，小明在执行查询的时候，会去判断当前这条数据的trx\_id\<read view的low\_limit\_id，显然都小于，所以小明会正常查询到id=1,2的两条记录，而不会受到小红修改的影响。

这时候，小红的修改也完成了，小红数据于是就变成了这样。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb9cc856e16a46479da6e191b9810dd7~tplv-k3u1fbpfcp-zoom-1.image)

如果小明再次去查询的话，就会发现现在的trx\_id>read view的low\_limit\_id，也就是4>3，不符合条件，同时发现现在的trx\_id=4在low\_limit\_id和up\_limit\_id \[3,5]之间，并且trx\_id=4在m\_ids=\[3,4]之中，所以就会根据roll\_pointer指向的undo log去查找，trx\_id=1小于现在的low\_limit\_id=3，符合条件，就找到了上一个版本name=张三的记录。

如果这时候小明自己去修改这条记录的值，把名字改成张五，结果就是这样。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/073fd38372f34e499be5e04ccd13494d~tplv-k3u1fbpfcp-zoom-1.image)

然后小明去查询的话，就会发现当前的trx\_id=3就是自己的creator\_trx\_id，就是自己，那么就直接返回这条数据。

所以，我们可以先总结下几种情况：

1.  如果`trx_id<low_limit_id`，那么说明就是之前事务的数据，直接返回，也就对应了小明第一次开启事务查询的场景
2.  如果`trx_id>low_limit`，trx\_id还在`[low_limit_id,up_limit_id]`范围之内，并且trx\_id在m\_ids中，就会根据`roll_pointer`去查找`undo log`日志链，找到之前版本的数据，对应的就是小红修改后小明再次查询的场景
3.  如果`trx_id=creator_trx_id`，那么说明就是自己修改的，直接返回就好了，对应的就是小明自己去修改数据的场景

### 不同隔离级别的实现

根据上面阐述的原理，你可能发现了，这是可重复读下的实现啊，保证每次读取到的数据都是一致的。

那么，如果是读已提交级别下，这个是怎么实现的？

其实很简单，在上面的原理解释中，我都是假设每次查询的时候生成了read view，后续并没有重新生成。

而读已提交级别下，则是每次查询都会生成一次read view。

以上述小红修改过张三后的场景来举例。

![图片](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ccfb25a9b50f4c349bc9a0d072994f51~tplv-k3u1fbpfcp-zoom-1.image)

在可重复度级别下，由于trx\_id>low\_limit，trx\_id还在\[low\_limit\_id,up\_limit\_id]范围之内，并且trx\_id在m\_ids中，满足我们上述的条件2，所以就会根据roll\_pointer找到之前的版本记录，保证可重复读。

而在读已提交的级别下，重新生成了read view，这时候trx\_id不在m\_ids之中，说明事务已经提交，所以可以直接返回这条数据，所以查到的数据就是小红修改后的`name=张三三`的数据了。

## 24. 什么buffer Pool （性能优化的一个点）


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a9883a3ba9a74fc7a744298db003a4c8~tplv-k3u1fbpfcp-watermark.image?)

buffer pool是mysql的一个缓冲区，缓存表数据与索引数据，把磁盘上的数据加载到缓冲区，避免每次访问都进行磁盘IO，起到加速访问的作用，因此有buffer pool当内存缓冲区，能够在每次读取先从buffer pool中读取，有的就不需要从磁盘读取

### 脏页

buffer pool中改了数据，但是还没同步到磁盘中的数据叫做脏页

### 刷脏

buffer pool将没有同步的数据同步到磁盘中交刷脏

刷脏是mysql会有一些线程，在空闲的时候把数据刷到磁盘中去

## 25. buffer Pool淘汰策略

冷热分区的LRU策略

LRU链表会被拆分为两部分，一部分为热数据，一部分为冷数据，热数据5/8，冷数据3/8


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/81fda85af898418f8db0ea7f032467c9~tplv-k3u1fbpfcp-watermark.image?)

### 数据页第一次加载进来，放在LRU链表的什么地方

放在冷数据区域的头部，不能直接在尾部，不然就直接被淘汰掉了

### 冷数据区域的缓存页什么时候放入热数据区域？

Mysql设定了一个规则，在`innodb_old_blocks_time`参数，默认值是1s就是1000毫秒

意味着，只有把数据页加载进缓存里，再经过1s之后再次对此缓存页进行访问才会将缓存页放到LRU链表热数据区域的头部；

### 为什么是1s？？

因为通过预读机制和全表扫描加载进行的数据页通常是1s内就加载了很多，然后对他们访问一下，这都是在1s内完成，他们会存放在冷数据区域等待刷盘清空，基本上不太会有机会放入热数据区域，除非在1s后还有人访问，说明后续可能还会与人访问，才会放入热数据区域的头部。

> 在有一些专门做数据库查询的机器上，buffer pool的内存会设置到整个服务器内存的6成到8成

### buffer pool越大所带来的问题

如果buffer pool越大，buffer pool上的数据没有同步到磁盘中，当mysql宕机了，那数据就会丢失了，所以就需要一种持久化的机制，来保证buffer pool的内容写入到磁盘中去，因此需要redo log

## 26. Redo Log跟buffer Pool的关系

崩溃恢复 基本保障 系统自动重做

> InnoDB引入了一个日志文件，叫做redo log（重做日志），我们把所有对内存数据的修改操作写入日志文件，如果服务器出现了问题，就从这个日志文件里面读取数据，恢复数据，用它来实现事务的持久性

> Redo log有什么特点
>
> 1.  记录修改后的值 属于物理日志
> 2.  redos log的大小是固定的，前面的内容会被覆盖，所以不能用于数据回滚/数据恢复
> 3.  redo log是 innoDB存储殷勤实现的，并不是所有存储引擎都有的


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c0346423ed8741178fcd3b43f8ff82a1~tplv-k3u1fbpfcp-watermark.image?)

## 数据库优化

*   数据库最大连接数，默认151个，最大10w
*   设置`wait_timeout`超时时间

## 27. 一条更新语句要经历哪些流程


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4ebe5816845b4faa80d3be8b2a65e3b1~tplv-k3u1fbpfcp-watermark.image?)

1.  首先SQL语句传入到Server层
2.  会先查询再修改，先查询name=66的所在行，然后再修改为涛哥，
3.  接着会将修改的结果先更新到buffer pool中，
4.  接着会记录redo log，并且将这行记录状态设置prepare
5.  修改好了就可以提交事务
6.  写入binlog
7.  commit 提交事务
8.  将redo log里这里事务的相关记录状态设置为commit

## 28. 小表驱动大表

*   用小的数据集去驱动(*可理解为匹配*)大的数据集

表A有20条数据,表B有20万数据.外部执行一次连接,内部要执行多次.

​	按照小表驱动大表,即A驱动B

```java
for(20条){
    for(20万条){

    }
}
复制代码
```

​	大表驱动小表,即B驱动A

```java
for(20万){
    for(20条){
    }
}
复制代码
```

*   小的循环在外层,表连接需要20次
*   大的循环在外层,表连接需要20万次,浪费数据库资源

**总结:** 小表驱动大表的主要目的是通过减少表连接创建的次数,加快查询速度.

*   Exists和in的使用场景

```sql
SELECT * FROM A WHERE ID IN (SELECT ID FROM B)   
复制代码
```

当B表的数据较小时,IN 优于Exists.

```sql
SELECT * FROM A WHERE  EXISTS (SELECT 1 FROM B WHERE B.ID = A.ID)
复制代码
```

当A表的数据集小于B表时,用Exists优于IN.

<https://juejin.cn/post/6988852674636546085>

## 29. 为什么Mysql要使用B+树做为索引

### 为什么采用B树

因为B树可以减少IO次数，如果单用一个二叉树，深度会很深，如果都是分2个，1000w数据，那就有500w层次，所以需要用多路查找树

而B+树是B树的增强，

B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。

B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。

> B+树能显著减少IO次数，提高效率
>
> B+树的查询效率更稳定，因为数据放在叶子节点
>
> B+树能提高范围查询的效率，因为叶子节点指向下一个叶子节点
>
> B+树采用顺序读

## 30. 磁盘的顺序读以及随机读有什么区别？


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8dfabc4910ba4f66ac9b9ee026f2f69c~tplv-k3u1fbpfcp-watermark.image?)

硬盘的盘底有多个盘片叠在一起，这个盘片在出厂的时候就完成了格式化，这个硬盘初始化会有两个同心圆，然后还有不同半径的磁道，磁道上就是放数据的，磁道会被划分为很多个扇区

扇区默认是512字节，这个磁盘有个磁头，磁头会去读数据，主轴会一直转

### 磁盘是如何完成单词IO的

寻道时间 + 旋转延迟 + 传送时间

> 随机读

比如两个数据在不同的扇区，磁头需要等主轴转到相应数据在的扇区，这就是随机读，两次IO需要比较大的移动动作，才可以读写数据

> 顺序读

比如B+树读取的都是连续的数据，读完一块数据立马能读到，这就是顺序读，可以连续的去访问这个一个IO

### 顺序IO与并发IO

> 顺序IO

磁盘控制器可能会一次发出一连串的IO命令，如果磁盘组一次只能执行一个IO，一个个的走，这就是顺序IO

> 并发IO

如果磁盘组性能很好，有多个磁盘，多个磁盘一起去处理IO

## 31. 索引的使用

### 列的散列值

散列度的公式：

> 不同值的数量：列的全部不同值和所有数据行的比例，越接近1，散列度越高；越接近0，散列度越低
>
> 例如性别只有男女，数据有100条，那么散列度就是1/50 散列度就比较低
>
> 例如身份证号每个人都有自己的身份证号，100条数据，那么散列度就是100/100 散列度就比较高

散列度高的适合用索引，散列度低的不建议用索引

### 联合索引最左匹配


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dbdc55b66e2f48ce9dea0618b548d18a~tplv-k3u1fbpfcp-watermark.image?)

## 32. 索引的创建与使用


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c208d6eeea524e68a851d63aef7c2880~tplv-k3u1fbpfcp-watermark.image?)

比如创建索引a，b；干脆创建(a,b)索引

## 33. Hash索引


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8ff681271c024b3da6c07e7758e50928~tplv-k3u1fbpfcp-watermark.image?)
hash索引的效率很高，不需要像B树 B+树那样一层一层的找，根据索引字段值，生成了一个hashcode，根据hashcode会映射一个磁盘地址，就找到了完整的数据。

> 局限性

因为经过hashcode映射后的地址，不一定是连续性的，是离散分布的，如果是做范围查询的话就不适用了

同时运用了hash就会有另外一个hash冲突的问题，比如链表法、开放寻址；加入这些后效率又会变低了；

## 34. 数据库什么时候会出现事务

比如执行：

`update user set name = '张三' where id = 1`

实际上它自动开启了一个事务，并且提交了，所以最终写入了磁盘，这个是开启事务的第一种方式，是自动开启和自动提交


![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d7cc27f4632042169c0f7e4a145518bc~tplv-k3u1fbpfcp-watermark.image?)

> 还有手动开启事务的方式

```mysql
# 开启事务
begin;
start Transaction;
# 结束事务
commit;
ROLLBACK;
客户端断开连接；
```

## 36. 如何解决数据的读一致性问题

两大方案：

> LBCC


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ae859786388439e9e977eec1a41ad98~tplv-k3u1fbpfcp-watermark.image?)

> MVCC

前面

## 37. 全局锁

全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

对于支持事务的存储引擎来说，mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。

> FTWRL与–single-transaction的区别
>
> \*\*single-transaction方法只适用于所有的表使用事务引擎的库。\*\*如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。

> 另外一个全库只读的方式 **set global readonly=true**

但我还是会建议你用FTWRL方式

*   一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。
*   二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高

## 38. 表级锁

> 表锁

\*\*表锁的语法是 lock tables … read/write。\*\*与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

> **MDL（metadata lock)**

MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

*   读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
*   读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

虽然MDL锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2f45aedf047f4afbb56234e00cde67d3~tplv-k3u1fbpfcp-watermark.image?)

*   session A先启动，这时候会对表t加一个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执行。

*   session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被阻塞。

*   如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。

*   如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。

### **如何安全地给小表加字段**

首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的`information_schema` 库的 `innodb_trx` 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。

但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？

这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。

MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持`DDL NOWAIT/WAIT n`这个语法。

## 39. 行级锁（怎么减少行锁对性能的影响？）

> 行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。

### 两阶段锁


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/115b0e62d4e94a0cad591389506281dd~tplv-k3u1fbpfcp-watermark.image?)

事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。

**在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是`两阶段锁协议`。**

所以

> 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放

### 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/670bb70c86ec483fbe0d9d91eccb8cbc~tplv-k3u1fbpfcp-watermark.image?)

这时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

*   一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb\_lock\_wait\_timeout来设置。
*   另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb\_deadlock\_detect设置为on，表示开启这个逻辑。

> innodb\_lock\_wait\_timeout

这个超时时间不能等待太长，同时也不能设置的很小，比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。

> innodb\_deadlock\_detect

一般采用主动死锁检测

它有个问题：

每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。

### 怎么解决由这种热点行更新导致的性能问题呢？

问题的症结在于，死锁检测要耗费大量的CPU资源。

*   **一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。**

    *   这种有一定风险性，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。

*   **另一个思路是控制并发度**

    *   根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到3000。

        因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。

> 如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：

*   第一种，直接执行delete from T limit 10000;
*   第二种，在一个连接中循环执行20次 delete from T limit 500;
*   第三种，在20个连接中同时执行delete from T limit 500。

你会选择哪一种方法呢？为什么呢？

第二种方式是相对较好的。

第一种方式（即：直接执行delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。

第三种方式（即：在20个连接中同时执行delete from T limit 500），会人为造成锁冲突。

## 40. Mysql慢查询

MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long\_query\_time值的SQL，则会被记录到慢查询日志中。long\_query\_time的默认值为10，意思是运行10S以上的语句。

默认情况下，Mysql数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。

> 相关参数

slow\_query\_log  ：是否开启慢查询日志，1表示开启，0表示关闭。

log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host\_name-slow\.log

slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host\_name-slow\.log

long\_query\_time ：慢查询阈值，当查询时间多于设定的阈值时，记录日志。

```sql
# 查看是否开启慢查询
show variables  like '%slow_query_log%';

# 开启慢查询
set global slow_query_log=1;
```

> 查询mysql服务器状态得命令

```mysql
SHOW GLOBAL STATUS

# 查询select执行次数
SHOW GLOBAL STATUS Like ‘com_select’

show processlist;
select * from information_schema.processlist;
```

## 41. EXPLAIN 解读

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de08275392e14e95ae9229cd00012d5e~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom: 80%;">

> id

该语句的唯一标识。如果explain的结果包括多个id值，则数字越大越先执行；而对于相同id的行，则表示从上往下依次执行。

> select\_type

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1cf1f01ad8c14430bf1277489d1c816f~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:80%;">

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/422bb9c6b52b45fab79f28206ea4f8f4~tplv-k3u1fbpfcp-zoom-1.image" alt="img" style="zoom:80%;">

> type

连接类型， ALL, index,  range, ref, eq\_ref, const, system, NULL（从左到右，性能从差到好）

*   `system`: 表中只有一条数据. 这个类型是特殊的 `const` 类型.

*   `const`: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.

*   `eq_ref`: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 `=`, 查询效率较高

*   `ref`: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 `最左前缀` 规则索引的查询.

*   `range`: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中.
    当 `type` 是 `range` 时, 那么 EXPLAIN 输出的 `ref` 字段为 NULL, 并且 `key_len` 字段是此次查询中使用到的索引的最长的那个.

*   `index`: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.
